{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow of MUTIS\n",
    "\n",
    "Here we illustrate the workflow of MUTIS (class version) to analyze correlation between two signals.\n",
    "The general workflow is:\n",
    "\n",
    "- **We load the data** in a suitable way.\n",
    "\n",
    "- **We generate the synthetic light curves**, which are used to calculate the confidence levels of correlations.\n",
    "    \n",
    "    This is an automatic process if the method used for generating them is just **sampling** (lc_gen_samp), or flux randomization with the same **psd** (lc_gen_psd). If we simulate them as an **stochastic** process (lc_gen_ou) as suggested for example in Tavecchio, Bonnoli and Galanti, 2020 (doi:10.1093/mnras/staa2055) we need to carefully choose the parameters for this stochastic process (currently trying to optimize it).\n",
    "    \n",
    "- **We generate the correlations** (the synthetic ones and the real one) and plot them together.\n",
    "    \n",
    "    For this we need to manually choose the time binning.\n",
    "\n",
    "**Juan Escudero**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# I'm doing a lot of changes to MUTIS while writting this, better reload automatically.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "from astropy.time import Time\n",
    "\n",
    "import matplotlib as mplt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mutis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "Load it with pandas becase I like the way pandas prints tables. Also useful accesing vars as strings!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['3mm'] = pd.read_csv('data/mm-I.dat', comment='!')\n",
    "data['3mm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['gamma'] = pd.read_csv('data/gamma-I.dat', comment='!')\n",
    "data['gamma']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, figsize=(12,4), sharex=True, gridspec_kw={'hspace':0.00})\n",
    "\n",
    "\n",
    "ax[0].errorbar(data['gamma']['jyear'], data['gamma']['CFlux'], data['gamma']['CFluxErr'], fmt='b.--', label='Gamma-ray flux (0.1 to 200 GeV)', lw=1) # freq?\n",
    "ax[0].set_ylabel('$\\gamma/\\mathrm{cm}^2/\\mathrm{s}?$')\n",
    "ax[0].legend()\n",
    "ax[0].grid()\n",
    "\n",
    "ax[1].errorbar(data['3mm']['jyear'], data['3mm']['I'], data['3mm']['dI'], fmt='k.--', label='mm', lw=1)  #data['3mm'].plot(x='year', y='I')\n",
    "ax[1].set_ylabel('Jy')\n",
    "ax[1].legend()\n",
    "ax[1].grid()\n",
    "\n",
    "fig.suptitle('Test Source Flux Density')\n",
    "plt.xlabel('years')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose data and methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the signals to correlate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1, s1, ds1 = data['3mm']['jyear'], data['3mm']['I'], data['3mm']['dI']\n",
    "t2, s2, ds2 = data['gamma']['jyear'], 1e6*data['gamma']['CFlux'], 1e6*data['gamma']['CFluxErr'] ### Â¡Use sensible units!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create signals with the corresponding data and choose the method for generating the light curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig1 = mutis.Signal(t1, s1, ds1, 'lc_gen_psd_nft')\n",
    "sig2 = mutis.Signal(t2, s2, ds2, 'lc_gen_ou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the correlation with the corresponding signals and choose the method for generating the correltions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = mutis.Correlation(sig1, sig2, 'welsh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate synthetic light curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **HUMAN INTERVENTION**\n",
    " \n",
    "Chose good parameters for time binning!\n",
    "\n",
    "Good parameters will have a high and similar $n_i$ for all bins, with bins covering most of the time range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation.gen_times(dtmin=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation.plot_times()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HUMAN INTERVENTION**\n",
    "\n",
    "If the method for generating the synthetic light curves is **lc_gen_ou** we need to chose a good set of parameters. \n",
    "\n",
    "In this case we have set only sig2's method to be lc_gen_ou because lc_gen_psd is more or less okey for sig1.\n",
    "\n",
    "The Signal class includes methods to deal with this OU parameter extraction. This could be more or less an authomathic process, but for some (not a negible number of) cases degenerancy of these OU parameter makes human intervention necessary. We need:\n",
    "1. To plot the histogram and check if the supposed probability density function (pdf) fits nicely (several ways: curve fitting or MLE).\n",
    "2. To check if the stimates are reasonable and produce nice light curves.\n",
    "3. Actually generate the light curves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the histogram and get extracted parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fits = sig2.OU_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check if this parameters generate nice light curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "sig2.check_gen(fgen='lc_gen_ou', fgen_params=dict(theta=17.8, mu=0.14, sigma=5.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set the parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig2.OU_theta, sig2.OU_mu, sig2.OU_sigma = 17.8, 0.13, 5.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Actually generate the synthetic light curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "correlation.gen_synth(400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate and plot correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "correlation.gen_corr();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation.plot_corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(correlation.peak_find())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
